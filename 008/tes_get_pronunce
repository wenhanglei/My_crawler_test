#!/usr/bin/env python
# -*- coding: utf-8 -*-
import requests
from bs4 import BeautifulSoup
import urllib.parse
import re

url = 'http://hanyu.baidu.com/'
h_file = 'header.txt'

#通过header.txt载入用于设置request的header
def load_header(filename):
    header = {}
    with open(filename) as file:
        for line in file:
            key,value = line.rstrip().split(':', maxsplit=1)
            header[key] = value
    return header

#获取所有的script标签资源
def get_script_link(url):
    links = []
    header = load_header('header.txt')
    resp = requests.get(url)
    resp.encoding = 'utf-8'
    bsobj = BeautifulSoup(resp.text, 'html.parser')
    spts = bsobj.find_all('script')
    for spt in spts:
        if 'src' in spt.attrs:
            links.append(spt['src'])
    return links

#保存对象到指定文件
def save_obj(obj, fname):
    import pickle
    with open(fname, 'wb') as file:
        pickle.dump(obj, file)

#从指定文件读取数据
def load_obj(fname):
    import pickle
    with open(fname, 'rb') as file:
        return pickle.load(file)

def query_word(string):
    string = 'http://hanyu.baidu.com/s?wd=%s&from=poem' % string
    urlcode = urllib.parse.quote(string, safe='?:/&=', encoding='utf-8')
    return urlcode

def get_pronounce(word):
    header = load_header(h_file)
    query_url = query_word(word)
    resp = requests.get(query_url, headers=header)
    resp.encoding = 'utf-8'
    bsobj = BeautifulSoup(resp.text, 'html.parser')
    div = bsobj.find('div', class_='pronounce')
    pron = div.span.b.string
    return pron

if __name__ == '__main__':
    pron = get_pronounce('谶')
    print(pron)