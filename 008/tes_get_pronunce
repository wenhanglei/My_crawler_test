#!/usr/bin/env python
# -*- coding: utf-8 -*-
# import requests
# from bs4 import BeautifulSoup
# import urllib.parse
# import re

url = 'http://hanyu.baidu.com/'
h_file = 'header.txt'

#通过header.txt载入用于设置request的header
def load_header(filename):
    header = {}
    with open(filename) as file:
        for line in file:
            key,value = line.rstrip().split(':', maxsplit=1)
            header[key] = value
    return header

#获取所有的script标签资源
def get_script_link(url):
    links = []
    header = load_header('header.txt')
    resp = requests.get(url)
    resp.encoding = 'utf-8'
    bsobj = BeautifulSoup(resp.text, 'html.parser')
    spts = bsobj.find_all('script')
    for spt in spts:
        if 'src' in spt.attrs:
            links.append(spt['src'])
    return links

#保存对象到指定文件
def save_obj(obj, fname):
    import pickle
    with open(fname, 'wb') as file:
        pickle.dump(obj, file)

#从指定文件读取数据
def load_obj(fname):
    import pickle
    with open(fname, 'rb') as file:
        return pickle.load(file)

text = '中文'
print(ord('中').to_bytes(2,'big'))
print(ord('文').to_bytes(2,'big'))

print(text.encode('utf-8'))
for b in text.encode('utf-8'):
    print(bin(b), end=' ')
print()
for b in text.encode('utf-8'):
    print((b), end=' ')

